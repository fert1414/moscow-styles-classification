{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f2cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from functools import partialmethod\n",
    "\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522b7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, train_transforms, val_transforms, dir_train, dir_val, batch_size):\n",
    "        \n",
    "        self.train_transforms = train_transforms\n",
    "        self.val_transforms = val_transforms\n",
    "\n",
    "        self.dir_train = dir_train\n",
    "        self.dir_val = dir_val\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        train_data = torchvision.datasets.ImageFolder(self.dir_train, self.train_transforms)\n",
    "        val_data = torchvision.datasets.ImageFolder(self.dir_val, self.val_transforms)\n",
    "\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size = self.batch_size, shuffle = True, num_workers = self.batch_size)\n",
    "        self.val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_data, batch_size = self.batch_size, shuffle = True, num_workers = self.batch_size)\n",
    "        \n",
    "def train_model(model, loss, optimizer, sheduler, epochs, train_dataloader, val_dataloader):\n",
    "\n",
    "    results = {\n",
    "        'train_loss_history': [],\n",
    "        'train_accuracy_history': [],\n",
    "        'val_loss_history': [],\n",
    "        'val_accuracy_history': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                sheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0\n",
    "            running_accuracy = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloader):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim = 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss_value.item()\n",
    "                running_accuracy += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_accuracy = running_accuracy / len(dataloader)\n",
    "\n",
    "            if phase == 'train':\n",
    "                results['train_accuracy_history'].append(epoch_accuracy)\n",
    "                results['train_loss_history'].append(epoch_loss)\n",
    "            else:\n",
    "                results['val_accuracy_history'].append(epoch_accuracy)\n",
    "                results['val_loss_history'].append(epoch_loss)\n",
    "\n",
    "    print('model training has been completed')\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161bacd",
   "metadata": {},
   "source": [
    "### Пайплайн обучения моделей resnet18, resnet50, resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dir_train = './data/processed_data/train'\n",
    "dir_val = './data/processed_data/val'\n",
    "\n",
    "DataLoader_resnet = DataLoader(train_transforms, val_transforms, dir_train, dir_val, 8)\n",
    "\n",
    "results = {}\n",
    "\n",
    "resnet_models = {\n",
    "    'resnet18': torchvision.models.resnet18(pretrained = True),\n",
    "    'resnet50': torchvision.models.resnet50(pretrained = True),\n",
    "    'resnet152': torchvision.models.resnet152(pretrained = True)\n",
    "}\n",
    "\n",
    "for model in resnet_models:\n",
    "    for param in resnet_models[model].parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    resnet_models[model].fc = torch.nn.Linear(resnet_models[model].fc.in_features, 11)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(resnet_models[model].parameters(), lr = 1.0e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "    results[model] = train_model(resnet_models[model], loss, optimizer, scheduler, 100,\n",
    "                                 DataLoader_resnet.train_dataloader, DataLoader_resnet.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3c8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resnet18 = pd.DataFrame(results['resnet18'])\n",
    "results_resnet50 = pd.DataFrame(results['resnet50'])\n",
    "results_resnet152 = pd.DataFrame(results['resnet152'])\n",
    "\n",
    "results_resnet18['val_accuracy_history'] = [i.item() for i in results_resnet18['val_accuracy_history'].to_list()]\n",
    "results_resnet18['train_accuracy_history'] = [i.item() for i in results_resnet18['train_accuracy_history'].to_list()]\n",
    "results_resnet50['val_accuracy_history'] = [i.item() for i in results_resnet50['val_accuracy_history'].to_list()]\n",
    "results_resnet50['train_accuracy_history'] = [i.item() for i in results_resnet50['train_accuracy_history'].to_list()]\n",
    "results_resnet152['val_accuracy_history'] = [i.item() for i in results_resnet152['val_accuracy_history'].to_list()]\n",
    "results_resnet152['train_accuracy_history'] = [i.item() for i in results_resnet152['train_accuracy_history'].to_list()]\n",
    "\n",
    "results_resnet18.to_csv('./models_results/resnet18.csv')\n",
    "results_resnet50.to_csv('./models_results/resnet50.csv')\n",
    "results_resnet152.to_csv('./models_results/resnet152.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e35127",
   "metadata": {},
   "source": [
    "### Пайплайн обучения моделей resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e774a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Neurons\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Python\\Neurons\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "d:\\Python\\Neurons\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training has been completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m optimizer = torch.optim.Adam(resnet152_2.parameters(), lr = \u001b[32m2.0e-3\u001b[39m)\n\u001b[32m     47\u001b[39m scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = \u001b[32m7\u001b[39m, gamma = \u001b[32m0.1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m resnet152_results[\u001b[33m'\u001b[39m\u001b[33mresnet152_2\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet152_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mDataLoader_resnet152\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataLoader_resnet152\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Шаг изменения градиента = 10\u001b[39;00m\n\u001b[32m     53\u001b[39m resnet152_3 = torchvision.models.resnet152(pretrained = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, loss, optimizer, sheduler, epochs, train_dataloader, val_dataloader)\u001b[39m\n\u001b[32m     38\u001b[39m running_loss = \u001b[32m0\u001b[39m\n\u001b[32m     39\u001b[39m running_accuracy = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\Neurons\\venv\\Lib\\site-packages\\tqdm\\std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\Neurons\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\Neurons\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1478\u001b[39m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent_workers:\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1483\u001b[39m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[32m   1484\u001b[39m \n\u001b[32m   1485\u001b[39m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\Neurons\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1628\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1623\u001b[39m         \u001b[38;5;28mself\u001b[39m._mark_worker_as_unavailable(worker_id, shutdown=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._workers:\n\u001b[32m   1625\u001b[39m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[32m   1626\u001b[39m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[32m   1627\u001b[39m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1628\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_queues:\n\u001b[32m   1630\u001b[39m     q.cancel_join_thread()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Soft\\programming\\python\\Lib\\multiprocessing\\process.py:149\u001b[39m, in \u001b[36mBaseProcess.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parent_pid == os.getpid(), \u001b[33m'\u001b[39m\u001b[33mcan only join a child process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcan only join a started process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_popen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     _children.discard(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Soft\\programming\\python\\Lib\\multiprocessing\\popen_spawn_win32.py:112\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    110\u001b[39m     msecs = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m + \u001b[32m0.5\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res == _winapi.WAIT_OBJECT_0:\n\u001b[32m    114\u001b[39m     code = _winapi.GetExitCodeProcess(\u001b[38;5;28mself\u001b[39m._handle)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees = (0, 20)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dir_train = './data/processed_data/train'\n",
    "dir_val = './data/processed_data/val'\n",
    "\n",
    "DataLoader_resnet152 = DataLoader(train_transforms, val_transforms, dir_train, dir_val, 8)\n",
    "\n",
    "resnet152_results = {}\n",
    "\n",
    "resnet152_1 = torchvision.models.resnet152(pretrained = True)\n",
    "\n",
    "# Шаг градиентного спуска = 0.001\n",
    "for param in resnet152_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet152_1.fc = torch.nn.Linear(resnet152_1.fc.in_features, 11)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer_1 = torch.optim.Adam(resnet152_1.parameters(), lr = 1.0e-3)\n",
    "scheduler_1 = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "resnet152_results['resnet152_1'] = train_model(resnet152_1, loss, optimizer_1, scheduler_1, 20, \n",
    "                                               DataLoader_resnet152.train_dataloader, DataLoader_resnet152.val_dataloader)\n",
    "\n",
    "# Шаг градиентного спуска = 0.002\n",
    "resnet152_2 = torchvision.models.resnet152(pretrained = True)\n",
    "\n",
    "for param in resnet152_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet152_2.fc = torch.nn.Linear(resnet152_2.fc.in_features, 11)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer_2 = torch.optim.Adam(resnet152_2.parameters(), lr = 2.0e-3)\n",
    "scheduler_2 = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "resnet152_results['resnet152_2'] = train_model(resnet152_2, loss, optimizer_2, scheduler_2, 20,\n",
    "                                               DataLoader_resnet152.train_dataloader, DataLoader_resnet152.val_dataloader)\n",
    "\n",
    "# Шаг изменения градиента = 10\n",
    "resnet152_3 = torchvision.models.resnet152(pretrained = True)\n",
    "\n",
    "for param in resnet152_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet152_3.fc = torch.nn.Linear(resnet152_3.fc.in_features, 11)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer_3 = torch.optim.Adam(resnet152_3.parameters(), lr = 1.0e-3)\n",
    "scheduler_3 = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)\n",
    "\n",
    "resnet152_results['resnet152_3'] = train_model(resnet152_3, loss, optimizer_3, scheduler_3, 20,\n",
    "                                               DataLoader_resnet152.train_dataloader, DataLoader_resnet152.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd49c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resnet152_1 = pd.DataFrame(resnet152_results['resnet152_1'])\n",
    "results_resnet152_2 = pd.DataFrame(resnet152_results['resnet152_2'])\n",
    "results_resnet152_3 = pd.DataFrame(resnet152_results['resnet152_3'])\n",
    "\n",
    "results_resnet152_1['val_accuracy_history'] = [i.item() for i in results_resnet152_1['val_accuracy_history'].to_list()]\n",
    "results_resnet152_1['train_accuracy_history'] = [i.item() for i in results_resnet152_1['train_accuracy_history'].to_list()]\n",
    "results_resnet152_2['val_accuracy_history'] = [i.item() for i in results_resnet152_2['val_accuracy_history'].to_list()]\n",
    "results_resnet152_2['train_accuracy_history'] = [i.item() for i in results_resnet152_2['train_accuracy_history'].to_list()]\n",
    "results_resnet152_3['val_accuracy_history'] = [i.item() for i in results_resnet152_3['val_accuracy_history'].to_list()]\n",
    "results_resnet152_3['train_accuracy_history'] = [i.item() for i in results_resnet152_3['train_accuracy_history'].to_list()]\n",
    "\n",
    "results_resnet152_1.to_csv('./models_results/resnet152_1.csv')\n",
    "results_resnet152_2.to_csv('./models_results/resnet152_2.csv')\n",
    "results_resnet152_3.to_csv('./models_results/resnet152_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e6e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
